{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step Count From Video\n",
    "\n",
    "### Overview\n",
    "Count the number of steps from a carefully controlled treadmill video. We identify a unique color in a region of interest (ROI), such as a shoelace. This color is tracked and the number of zero crossing (normalized) is correlated to a step. Specifically create an object around the the color of interest and track the trajectory in Euclidean space (x,y). Zero crossings are estimated by identifing the zero slope and inflection point of the y coordinate time series.\n",
    "\n",
    "### Improvements\n",
    "Automate ROI \n",
    "Physically place unique color tags (neon stickers) on shoes during test\n",
    "Automate start and stop frames\n",
    "Consider contours in Visualization\n",
    "Test accuracy over various test scenarios\n",
    "Consider transforming to HSV space to mitigate shadows\n",
    "Automate setting of kernel size (for object detect) and mask threshold\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and System Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: MacOSX\n",
      "Using OpenCV for python version 3.1.0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib auto\n",
    "print('Using OpenCV for python version %s'%cv2.__version__)\n",
    "\n",
    "# system parameters\n",
    "# Display tracking Video and Debug Messages\n",
    "#DISP = True\n",
    "DISP = False\n",
    "\n",
    "# size of kernel\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (8,8))\n",
    "\n",
    "# +/- in RGB color space\n",
    "offset = 20\n",
    "\n",
    "# file to interrogate\n",
    "filname = '.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def onclick(event):\n",
    "    print('button=%d, x=%d, y=%d, xdata=%f, ydata=%f' %\n",
    "          (event.button, event.x, event.y, event.xdata, event.ydata))\n",
    "    global idxList\n",
    "    idxList.append([event.xdata, event.ydata])\n",
    "#    global axRef\n",
    "#    axRef.scatter(int(event.xdata), int(event.ydata))\n",
    "    \n",
    "def getPoint(x,y,img):\n",
    "    temp = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    return temp[x,y]\n",
    "\n",
    "def getLineSegment(x1,x2,y,img):\n",
    "    temp = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    return temp[x1:x2,y]\n",
    "\n",
    "def colorFromIdx(idx, frame):\n",
    "    x,y = idx \n",
    "    return frame[int(y), int(x), :]\n",
    "\n",
    "def plotMask(idx, frame, offset):\n",
    "    idColor = colorFromIdx(idx, frame)\n",
    "    mask = np.zeros(frame.shape)\n",
    "    for ii,color in enumerate(idColor):\n",
    "        mask[:,:,ii] = (frame[:,:,ii] > color-offset) & (frame[:,:,ii]<color+offset)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.imshow(np.sum(mask,axis=2))\n",
    "    plt.title(str(idx))\n",
    "\n",
    "def plotRefPoint(idx, ax):\n",
    "    x,y = idx \n",
    "    ax.scatter(int(x), int(y))\n",
    "    \n",
    "def getMask(idColor, frame, offset):\n",
    "    mask = np.zeros(frame.shape)\n",
    "    for ii,color in enumerate(idColor):\n",
    "        mask[:,:,ii] = (frame[:,:,ii] > color-offset) & (frame[:,:,ii]<color+offset) \n",
    "    mask = np.sum(mask, axis=2) ==3\n",
    "    return mask\n",
    "\n",
    "def getBlob(mask):\n",
    "    blob = cv2.dilate(mask.astype(np.uint8), kernel)\n",
    "    return blob\n",
    "\n",
    "def getCentroid(blob):\n",
    "    temp = blob.copy()\n",
    "    temp[temp==0] = 255\n",
    "    temp[temp==1] = 0\n",
    "    keypoints = detector.detect(temp)\n",
    "#    keypoints = detector.detect(blob)\n",
    "    return keypoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manually select unique color pixel to track in ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x113dcf5c0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x111060048>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "button=1, x=290, y=176, xdata=47.833333, ydata=212.833333\n",
      "button=1, x=290, y=182, xdata=47.833333, ydata=207.833333\n",
      "button=1, x=290, y=187, xdata=47.833333, ydata=203.666667\n"
     ]
    }
   ],
   "source": [
    "idxList = []\n",
    "frameOffset = 300\n",
    "bufLen = 5\n",
    "\n",
    "# get these with mouse clicks later\n",
    "r,h,c,w = 150,320,290,160 \n",
    "\n",
    "# grab and display a frame during run\n",
    "cap = cv2.VideoCapture('test.mp4')\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES,frameOffset)\n",
    "fs = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "ret,frame = cap.read()\n",
    "# set up the ROI for tracking\n",
    "roiRef = frame[r:r+h, c:c+w]\n",
    "\n",
    "figRef = plt.figure()\n",
    "plt.title('Mouse Click on Possible Unique Pixels')\n",
    "axRef = figRef.add_subplot(111)\n",
    "axRef.imshow(roiRef)\n",
    "\n",
    "# mouse click on columns to histogram\n",
    "cid = figRef.canvas.mpl_connect('button_press_event', onclick);\n",
    "\n",
    "# Set up the SimpleBlobdetector with default parameters.\n",
    "params = cv2.SimpleBlobDetector_Params()\n",
    "\n",
    "# Change thresholds\n",
    "params.minThreshold = 0;\n",
    "params.maxThreshold = 256;\n",
    "\n",
    "# Filter by Area.\n",
    "params.filterByArea = True\n",
    "params.minArea = 5\n",
    "\n",
    "# Filter by Circularity\n",
    "params.filterByCircularity = False\n",
    "params.minCircularity = 0.1\n",
    "\n",
    "# Filter by Convexity\n",
    "params.filterByConvexity = False\n",
    "params.minConvexity = 0.5\n",
    "\n",
    "# Filter by Inertia\n",
    "params.filterByInertia = False\n",
    "params.minInertiaRatio = 0.5\n",
    "\n",
    "detector = cv2.SimpleBlobDetector_create(params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize selected Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "figRef.canvas.mpl_disconnect(cid)\n",
    "\n",
    "    \n",
    "for idx in idxList:    \n",
    "    plotMask(idx, roiRef, offset)\n",
    "    plotRefPoint(idx,axRef)\n",
    "    \n",
    "#add roi selection here\n",
    "#add automated point selection and closing of images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Track "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "figRef.canvas.mpl_disconnect(cid);\n",
    "\n",
    "# add user input to choose the best starting point\n",
    "idx = idxList[1] #always choose second point, change this to user input in above cell\n",
    "x,y = idx\n",
    "idColor = colorFromIdx(idx, roiRef)\n",
    "xBuff = [x]\n",
    "yBuff = [y]\n",
    "frameSkip = 0\n",
    "\n",
    "cap = cv2.VideoCapture('test.mp4')\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES,frameSkip)\n",
    "ret,frame = cap.read()\n",
    "count = 0\n",
    "\n",
    "while ret:\n",
    "    count = count + 1\n",
    "    roi = frame[r:r+h, c:c+w]\n",
    "    mask = getMask(idColor, roi, offset)\n",
    "    blob = getBlob(mask)\n",
    "    keypoints = getCentroid(blob)\n",
    "    \n",
    "    # if we find any blobs\n",
    "    if keypoints:\n",
    "        \n",
    "        # assume one and use that as the centroid\n",
    "        x,y = keypoints[0].pt\n",
    "        \n",
    "        # if more than one find the one closest to the last one\n",
    "        minVal = float('inf')\n",
    "        for kp in keypoints:\n",
    "            x,y = kp.pt\n",
    "            dist = np.power((x-xBuff[-1]),2)+np.power((y-yBuff[-1]),2)\n",
    "            if dist < minVal:\n",
    "                minVal = dist\n",
    "                xOut = x\n",
    "                yout = y\n",
    "                    \n",
    "                \n",
    "    else:\n",
    "        \n",
    "        # if no blob found then use the old value\n",
    "        # mostly we get here because the blob touches the edge of the image\n",
    "        x = xBuff[-1]\n",
    "        y = yBuff[-1]\n",
    "        #input('')\n",
    "        \n",
    "    xBuff.append(x)\n",
    "    yBuff.append(y)\n",
    "    \n",
    "    \n",
    "    if DISP:\n",
    "        \n",
    "        fr,fc,t = frame.shape\n",
    "        frameMask = np.ones([fr,fc],dtype=np.uint8)      \n",
    "        frameMask[r:r+h,c:c+w] = cv2.bitwise_xor(blob,1)        \n",
    "        new = cv2.circle(cv2.bitwise_and(frame, frame, mask=frameMask), (int(x)+c,int(y)+r), 5, 255, -1)\n",
    "        cv2.imshow('frame',new)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "            \n",
    "#         k = cv2.waitKey(0)\n",
    "#         if k == 27:         # wait for ESC key to exit\n",
    "#             cv2.destroyAllWindows()\n",
    "#             break\n",
    "#         elif k == ord('n'): # wait for 's' for next frame\n",
    "#             t = 1\n",
    "            \n",
    "    ret,frame = cap.read()\n",
    "\n",
    "\n",
    "cap.release()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Filter and count steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()\n",
    "\n",
    "# user input to figure out true offset\n",
    "frameOffset = 500\n",
    "\n",
    "# low pass filter to smooth\n",
    "N=10\n",
    "fc = fs/40.\n",
    "\n",
    "import scipy.signal as sp\n",
    "\n",
    "# use firwin with arbitrary Fs\n",
    "h=sp.firwin( numtaps=N, cutoff=fc, nyq=fs/2)\n",
    "filtY=sp.lfilter( h, 1.0, yBuff) # 'x' is the time-series data you are filtering\n",
    "\n",
    "\n",
    "# count number of positive inflextions points (first derivative zero / second neg)\n",
    "dy = np.diff(filtY)\n",
    "dy[dy>0] = 1\n",
    "dy[dy<0] = -1\n",
    "ddy = np.diff(dy)\n",
    "\n",
    "# this counts just one legg steps\n",
    "#ddy[ddy>0] = 0\n",
    "\n",
    "# if we assume a backswing == a forward swing with the other leg\n",
    "totalSteps = np.count_nonzero(ddy[frameOffset:25700])\n",
    "\n",
    "print('Total Steps = %d'%totalSteps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Debug Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "# plt.plot(filtY)\n",
    "#plt.plot(filtY[20000:])\n",
    "plt.plot(filtY,'.-')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%run 'import_plots.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ipplot(yBuff);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {
    "f0de84dde35f470f8efb5b23bfedae39": {
     "views": [
      {
       "cell_index": 16
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
