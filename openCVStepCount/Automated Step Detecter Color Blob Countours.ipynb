{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: MacOSX\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'3.1.0'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib auto\n",
    "\n",
    "cv2.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def onclick(event):\n",
    "    print('button=%d, x=%d, y=%d, xdata=%f, ydata=%f' %\n",
    "          (event.button, event.x, event.y, event.xdata, event.ydata))\n",
    "    global idxList\n",
    "    idxList.append([event.xdata, event.ydata])\n",
    "\n",
    "def getPoint(x,y,img):\n",
    "    temp = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    return temp[x,y]\n",
    "\n",
    "def getLineSegment(x1,x2,y,img):\n",
    "    temp = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    return temp[x1:x2,y]\n",
    "\n",
    "def colorFromIdx(idx, frame):\n",
    "    x,y = idx \n",
    "    return frame[int(y), int(x), :]\n",
    "\n",
    "def plotMask(idx, frame):\n",
    "    idColor = colorFromIdx(idx, frame)\n",
    "    offset = 20\n",
    "    mask = np.zeros(frame.shape)\n",
    "    for ii,color in enumerate(idColor):\n",
    "        mask[:,:,ii] = (frame[:,:,ii] > color-offset) & (frame[:,:,ii]<color+offset)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.imshow(np.sum(mask,axis=2))\n",
    "    plt.title(str(idx))\n",
    "\n",
    "def plotRefPoint(idx, ax):\n",
    "    x,y = idx \n",
    "    ax.scatter(int(x), int(y))\n",
    "    \n",
    "def getMask(idColor, frame):\n",
    "    offset = 20\n",
    "    mask = np.zeros(frame.shape)\n",
    "    for ii,color in enumerate(idColor):\n",
    "        mask[:,:,ii] = (frame[:,:,ii] > color-offset) & (frame[:,:,ii]<color+offset) \n",
    "    mask = np.sum(mask, axis=2) ==3\n",
    "    return mask\n",
    "\n",
    "def getBlob(mask, kernel):\n",
    "    blob = cv2.dilate(mask.astype(np.uint8), kernel)\n",
    "    return blob\n",
    "\n",
    "def getCentroid(blob):\n",
    "#     temp = blob.copy()\n",
    "#     temp[temp==0] = 255\n",
    "#     temp[temp==1] = 0\n",
    "#     keypoints = detector.detect(temp)\n",
    "    keypoints = detector.detect(blob)\n",
    "    return keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "button=1, x=290, y=181, xdata=47.833333, ydata=208.666667\n",
      "button=1, x=289, y=183, xdata=47.000000, ydata=207.000000\n",
      "button=1, x=289, y=183, xdata=47.000000, ydata=207.000000\n",
      "button=1, x=287, y=189, xdata=45.333333, ydata=202.000000\n"
     ]
    }
   ],
   "source": [
    "idxList = []\n",
    "\n",
    "frameOffset = 300\n",
    "bufLen = 5\n",
    "\n",
    "# get these with mouse clicks later\n",
    "r,h,c,w = 150,320,290,160 \n",
    "\n",
    "# grab and display a frame during run\n",
    "cap = cv2.VideoCapture('test.mp4')\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES,frameOffset)\n",
    "fs = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "ret,frame = cap.read()\n",
    "# set up the ROI for tracking\n",
    "roi = frame[r:r+h, c:c+w]\n",
    "\n",
    "figRef = plt.figure()\n",
    "axRef = figRef.add_subplot(111)\n",
    "axRef.imshow(roi)\n",
    "\n",
    "# mouse click on columns to histogram\n",
    "cid = figRef.canvas.mpl_connect('button_press_event', onclick);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "figRef.canvas.mpl_disconnect(cid);\n",
    "    \n",
    "for idx in idxList:    \n",
    "    plotMask(idx,roi)\n",
    "    plotRefPoint(idx,axRef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DISP = True\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (30,30))\n",
    "frameSkip = 0\n",
    "\n",
    "# add user input to choose the best starting point\n",
    "idx = idxList[1]\n",
    "x,y = idx\n",
    "idColor = colorFromIdx(idx, roi)\n",
    "xBuff = [x]\n",
    "yBuff = [y]\n",
    "\n",
    "cap = cv2.VideoCapture('test.mp4')\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES,frameSkip)\n",
    "ret,frame = cap.read()\n",
    "count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "getBlob() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-17c52a36980f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mframeMask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mblob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetBlob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframeMask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetStructuringElement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMORPH_ELLIPSE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mcontours\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheirarchy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindContours\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblob\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRETR_TREE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCHAIN_APPROX_SIMPLE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrawContours\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcontours\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: getBlob() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "# roi = frame[r:r+h, c:c+w]\n",
    "# mask = getMask(idColor, roi)\n",
    "# blob = getBlob(mask)\n",
    "# #contours, hierarchy = cv2.findContours(blob,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "roi = frame[r:r+h, c:c+w]\n",
    "mask = getMask(idColor, roi)\n",
    "fr,fc,t = frame.shape\n",
    "frameMask = np.zeros([fr,fc],dtype=np.uint8)\n",
    "frameMask[r:r+h,c:c+w] = mask\n",
    "\n",
    "blob = getBlob(frameMask, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (30,30)))\n",
    "contours, heirarchy, val =cv2.findContours(blob,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "cv2.drawContours(frame,contours,-1,(0,255,0),-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x11de84898>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A=cv2.dilate(frameMask.astype(np.uint8), cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (30,30)))\n",
    "plt.imshow(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x11dea4710>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.imshow(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "error",
     "evalue": "/Users/jenkins/miniconda/1/x64/conda-bld/work/opencv-3.1.0/modules/imgproc/src/drawing.cpp:2380: error: (-215) npoints > 0 in function drawContours\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-94-094015bef9d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcontours\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheirarchy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindContours\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRETR_TREE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCHAIN_APPROX_SIMPLE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrawContours\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcontours\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31merror\u001b[0m: /Users/jenkins/miniconda/1/x64/conda-bld/work/opencv-3.1.0/modules/imgproc/src/drawing.cpp:2380: error: (-215) npoints > 0 in function drawContours\n"
     ]
    }
   ],
   "source": [
    "contours, heirarchy, val =cv2.findContours(A,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "cv2.drawContours(A,contours,-1,(0,255,0),-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "?cv2.drawKeypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x11bb6f710>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.imshow(blob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "NameError",
     "evalue": "name 'keypoints' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-041935f6c02c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m# if we find any blobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mkeypoints\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# assume one and use that as the centroid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'keypoints' is not defined"
     ]
    }
   ],
   "source": [
    "DISP = True\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (30,30))\n",
    "frameSkip = 0\n",
    "\n",
    "# add user input to choose the best starting point\n",
    "idx = idxList[1]\n",
    "x,y = idx\n",
    "idColor = colorFromIdx(idx, roi)\n",
    "xBuff = [x]\n",
    "yBuff = [y]\n",
    "\n",
    "cap = cv2.VideoCapture('test.mp4')\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES,frameSkip)\n",
    "ret,frame = cap.read()\n",
    "count = 0\n",
    "\n",
    "while ret:\n",
    "    count = count + 1\n",
    "    roi = frame[r:r+h, c:c+w]\n",
    "    mask = getMask(idColor, roi)\n",
    "    fr,fc,t = frame.shape\n",
    "    frameMask = np.ones([fr,fc],dtype=np.uint8)\n",
    "    blob = getBlob(frameMask)\n",
    "    countour, heirarchy, val =cv2.findContours(blob,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cv2.drawContours(fram,contours,-1,(0,255,0),-1)\n",
    "\n",
    "    cv2.imshow('frame',new)\n",
    "#         if cv2.waitKey(20) & 0xFF == ord('q'):\n",
    "#             break\n",
    "    k = cv2.waitKey(0)\n",
    "    if k == 27:         # wait for ESC key to exit\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "    elif k == ord('n'): # wait for 's' for next frame\n",
    "        t = 1\n",
    "    \n",
    "#     # if we find any blobs\n",
    "#     if countour:\n",
    "        \n",
    "#         # assume one and use that as the centroid\n",
    "#         x,y = keypoints[0].pt\n",
    "        \n",
    "#         # if more than one find the one closest to the last one\n",
    "#         minVal = float('inf')\n",
    "#         for kp in keypoints:\n",
    "#             x,y = kp.pt\n",
    "#             dist = np.power((x-xBuff[-1]),2)+np.power((y-yBuff[-1]),2)\n",
    "#             if dist < minVal:\n",
    "#                 minVal = dist\n",
    "#                 xOut = x\n",
    "#                 yout = y\n",
    "                    \n",
    "                \n",
    "#     else:\n",
    "        \n",
    "#         # if no blob found then use the old value\n",
    "#         # mostly we get here because the blob touches the edge of the image\n",
    "#         x = xBuff[-1]\n",
    "#         y = yBuff[-1]\n",
    "#         #input('')\n",
    "        \n",
    "#     xBuff.append(x)\n",
    "#     yBuff.append(y)\n",
    "    \n",
    "    \n",
    "#     if DISP:\n",
    "        \n",
    "#         fr,fc,t = frame.shape\n",
    "#         frameMask = np.ones([fr,fc],dtype=np.uint8)\n",
    "#         blob[blob==0]=255\n",
    "#         blob[blob==1]=0\n",
    "#         blob[blob==255]=1\n",
    "#         frameMask[r:r+h,c:c+w] = blob\n",
    "#         new = cv2.circle(cv2.bitwise_and(frame, frame, mask=frameMask), (int(x),int(y)), 5, 255, -1)\n",
    "#         cv2.imshow('frame',new)\n",
    "# #         if cv2.waitKey(20) & 0xFF == ord('q'):\n",
    "# #             break\n",
    "#         k = cv2.waitKey(0)\n",
    "#         if k == 27:         # wait for ESC key to exit\n",
    "#             cv2.destroyAllWindows()\n",
    "#             break\n",
    "#         elif k == ord('n'): # wait for 's' for next frame\n",
    "#             t = 1\n",
    "            \n",
    "    ret,frame = cap.read()\n",
    "\n",
    "\n",
    "cap.release()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x116e2a6a0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.imshow(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(frameMask[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-21-2f42c610920d>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-21-2f42c610920d>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    r,w,~ = frame.shape\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "r\n",
    "w\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-aacb4190c366>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'result' is not defined"
     ]
    }
   ],
   "source": [
    "plt.imshow(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-bcaee1fc5578>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdestroyAllWindows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# user input to figure out true offset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mframeOffset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "cv2.destroyAllWindows()\n",
    "\n",
    "# user input to figure out true offset\n",
    "frameOffset = 500\n",
    "\n",
    "# low pass filter to smooth\n",
    "N=10\n",
    "fc = fs/40.\n",
    "\n",
    "import scipy.signal as sp\n",
    "\n",
    "# use firwin with arbitrary Fs\n",
    "h=sp.firwin( numtaps=N, cutoff=fc, nyq=fs/2)\n",
    "filtY=sp.lfilter( h, 1.0, yBuff) # 'x' is the time-series data you are filtering\n",
    "\n",
    "\n",
    "# count number of positive inflextions points (first derivative zero / second neg)\n",
    "dy = np.diff(filtY)\n",
    "dy[dy>0] = 1\n",
    "dy[dy<0] = -1\n",
    "ddy = np.diff(dy)\n",
    "ddy[ddy>0] = 0\n",
    "totalSteps = np.count_nonzero(ddy[frameOffset:25700])\n",
    "\n",
    "print('Total Steps = %d'%totalSteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11da22320>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x11ddfd1d0>]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x116a0c860>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x11f19d588>]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(np.power(yBuff,2)+np.power(xBuff,2))\n",
    "plt.figure()\n",
    "plt.plot(yBuff)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: ./Downloads/StepCountRateVideos/20161110_152638\\ KeDe\\ Step\\ Count.mp4: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "%ls './Downloads/StepCountRateVideos/20161110_152638\\ KeDe\\ Step\\ Count.mp4'"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
