{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step Count From Video\n",
    "\n",
    "### Overview\n",
    "Count the number of steps from a carefully controlled treadmill video. We identify a unique color in a region of interest (ROI), such as a shoelace. This color is tracked and the number of zero crossing (normalized) is correlated to a step. Specifically create an object around the the color of interest and track the trajectory in Euclidean space (x,y). Zero crossings are estimated by identifing the zero slope and inflection point of the y coordinate time series.\n",
    "\n",
    "### Improvements\n",
    "- <font color='red'>Automate ROI (DONE)</font> \n",
    "- Physically place unique color tags (neon stickers) on shoes during test-\n",
    "- Automate start and stop frames\n",
    "- Consider contours in Visualization\n",
    "- Test accuracy over various test scenarios\n",
    "- Consider transforming to HSV space to mitigate shadows\n",
    "- Automate setting of kernel size (for object detect) and mask threshold\n",
    "- Use history to track trajectory\n",
    "- <font color='red'>Minimum stride rate (DONE)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and System Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib osx\n",
    "print('Using OpenCV version %s'%cv2.__version__)\n",
    "print('Using Numpy version  %s'%np.__version__)\n",
    "ver = sys.version.split('|')\n",
    "print('Using python verion  %s'%ver[0])\n",
    "print('('+ver[1]+')')\n",
    "print(ver[2])\n",
    "\n",
    "# system parameters\n",
    "# Display tracking Video and Debug Messages\n",
    "#DISP = True\n",
    "DISP = True\n",
    "\n",
    "# size of kernel\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (8,8))\n",
    "\n",
    "# min blob size\n",
    "minBlobArea = 5\n",
    "\n",
    "# +/- in RGB color space\n",
    "offset = 20\n",
    "\n",
    "# file to interrogate\n",
    "filename = './Downloads/StepCountRateVideos/VID_20161118_111452 LoDa Step Rate 5.0-6.0.mp4'\n",
    "\n",
    "# frame window over which actual steps are taken\n",
    "startFrame = 500\n",
    "endFrame = 25700"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def onclick(event):\n",
    "    print('button=%d, x=%d, y=%d, xdata=%f, ydata=%f' %\n",
    "          (event.button, event.x, event.y, event.xdata, event.ydata))\n",
    "    global idxList\n",
    "    idxList.append([event.xdata, event.ydata])\n",
    "#    global axRef\n",
    "#    axRef.scatter(int(event.xdata), int(event.ydata))\n",
    "    \n",
    "def getPoint(x,y,img):\n",
    "    temp = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    return temp[x,y]\n",
    "\n",
    "def getLineSegment(x1,x2,y,img):\n",
    "    temp = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    return temp[x1:x2,y]\n",
    "\n",
    "def colorFromIdx(idx, frame):\n",
    "    x,y = idx \n",
    "    return frame[int(y), int(x), :]\n",
    "\n",
    "def plotMask(idx, frame, offset):\n",
    "    idColor = colorFromIdx(idx, frame)\n",
    "    mask = np.zeros(frame.shape)\n",
    "    for ii,color in enumerate(idColor):\n",
    "        mask[:,:,ii] = (frame[:,:,ii] > color-offset) & (frame[:,:,ii]<color+offset)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.imshow(np.sum(mask,axis=2))\n",
    "    plt.title(str(idx))\n",
    "\n",
    "def plotRefPoint(idx, ax):\n",
    "    x,y = idx \n",
    "    ax.scatter(int(x), int(y))\n",
    "    \n",
    "def getMask(idColor, frame, offset):\n",
    "    mask = np.zeros(frame.shape)\n",
    "    for ii,color in enumerate(idColor):\n",
    "        mask[:,:,ii] = (frame[:,:,ii] > color-offset) & (frame[:,:,ii]<color+offset) \n",
    "    mask = np.sum(mask, axis=2) ==3\n",
    "    return mask\n",
    "\n",
    "def getBlob(mask):\n",
    "    blob = cv2.dilate(mask.astype(np.uint8), kernel)\n",
    "    return blob\n",
    "\n",
    "def getCentroid(blob):\n",
    "    temp = blob.copy()\n",
    "    temp[temp==0] = 255\n",
    "    temp[temp==1] = 0\n",
    "    keypoints = detector.detect(temp)\n",
    "#    keypoints = detector.detect(blob)\n",
    "    return keypoints\n",
    "\n",
    "\n",
    "# Set up the SimpleBlobdetector with default parameters.\n",
    "params = cv2.SimpleBlobDetector_Params()\n",
    "\n",
    "# Change thresholds\n",
    "params.minThreshold = 0;\n",
    "params.maxThreshold = 256;\n",
    "\n",
    "# Filter by Area.\n",
    "params.filterByArea = True\n",
    "params.minArea = minBlobArea\n",
    "\n",
    "# Filter by Circularity\n",
    "params.filterByCircularity = False\n",
    "params.minCircularity = 0.1\n",
    "\n",
    "# Filter by Convexity\n",
    "params.filterByConvexity = False\n",
    "params.minConvexity = 0.5\n",
    "\n",
    "# Filter by Inertia\n",
    "params.filterByInertia = False\n",
    "params.minInertiaRatio = 0.5\n",
    "\n",
    "detector = cv2.SimpleBlobDetector_create(params)\n",
    "\n",
    "def trackSteps(idx, roiRef, DISP, filename, roiPoints):\n",
    "    \n",
    "    x,y = idx\n",
    "    r,c,h,w = roiPoints \n",
    "    idColor = colorFromIdx(idx, roiRef)\n",
    "    xBuff = [x]\n",
    "    yBuff = [y]\n",
    "    frameSkip = 0\n",
    "\n",
    "    cap = cv2.VideoCapture(filename)\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES,frameSkip)\n",
    "    ret,frame = cap.read()\n",
    "    count = frameSkip\n",
    "\n",
    "    while ret:\n",
    "        count = count + 1\n",
    "        roi = frame[r:h,c:w]\n",
    "\n",
    "        mask = getMask(idColor, roi, offset)\n",
    "        blob = getBlob(mask)\n",
    "        keypoints = getCentroid(blob)\n",
    "\n",
    "        # if we find any blobs\n",
    "        if keypoints:\n",
    "\n",
    "            # assume one and use that as the centroid\n",
    "            x,y = keypoints[0].pt\n",
    "\n",
    "            # if more than one find the one closest to the last one\n",
    "            minVal = float('inf')\n",
    "            for kp in keypoints:\n",
    "                x,y = kp.pt\n",
    "                dist = np.power((x-xBuff[-1]),2)+np.power((y-yBuff[-1]),2)\n",
    "                if dist < minVal:\n",
    "                    minVal = dist\n",
    "                    xOut = x\n",
    "                    yout = y\n",
    "\n",
    "\n",
    "        else:\n",
    "\n",
    "            # if no blob found then use the old value\n",
    "            # mostly we get here because the blob touches the edge of the image\n",
    "            x = xBuff[-1]\n",
    "            y = yBuff[-1]\n",
    "            #input('')\n",
    "\n",
    "        xBuff.append(x)\n",
    "        yBuff.append(y)\n",
    "           \n",
    "        if DISP and (count%1000 == 0):\n",
    "            print(count)\n",
    "\n",
    "        if DISP:\n",
    "\n",
    "            fr,fc,t = frame.shape\n",
    "            frameMask = np.ones([fr,fc],dtype=np.uint8)      \n",
    "            frameMask[r:h,c:w] = cv2.bitwise_xor(blob,1)        \n",
    "            new = cv2.circle(cv2.bitwise_and(frame, frame, mask=frameMask), (int(x)+c,int(y)+r), 5, 255, -1)\n",
    "            cv2.imshow('frame',new)\n",
    "\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "#             k = cv2.waitKey(0)\n",
    "#             if k == 27:         # wait for ESC key to exit\n",
    "#                 cv2.destroyAllWindows()\n",
    "#                 break\n",
    "#             elif k == ord('n'): # wait for 's' for next frame\n",
    "#                 t = 1\n",
    "\n",
    "        ret,frame = cap.read()\n",
    "\n",
    "\n",
    "    cap.release()\n",
    "    return [xBuff, yBuff]\n",
    "\n",
    "def trackPoints(filename, frameOffset, roiPoints):\n",
    "    r,h,c,w = roiPoints \n",
    "\n",
    "    # grab and display a frame during run\n",
    "    cap = cv2.VideoCapture(filename)\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES,frameOffset)\n",
    "    fs = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    ret,frame = cap.read()\n",
    "    # set up the ROI for tracking\n",
    "    roiRef = frame[r:r+h, c:c+w]\n",
    "           \n",
    "    cv2.namedWindow('select track points')\n",
    "    cv2.setMouseCallback('select track points',draw_circle)\n",
    "\n",
    "    while(1):\n",
    "        cv2.imshow('image',roiRef)\n",
    "        k = cv2.waitKey(1) & 0xFF\n",
    "        if k == ord('m'):\n",
    "            mode = not mode\n",
    "        elif k == 27:\n",
    "            break\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    " \n",
    "    # mouse click on columns to histogram\n",
    "    return [roiRef, fs]\n",
    "\n",
    "def countSteps(yBuff, startFrame, endFrame):\n",
    "    # user input to figure out true offset\n",
    "    threshStepSamples = 4 #min number of sample per stride based on max step rate\n",
    "\n",
    "    # low pass filter to smooth\n",
    "    N=10\n",
    "    fc = fs/600.\n",
    "\n",
    "    import scipy.signal as sp\n",
    "\n",
    "    # use firwin with arbitrary Fs\n",
    "    h=sp.firwin( numtaps=N, cutoff=fc, nyq=fs/2)\n",
    "    filtY=sp.lfilter( h, 1.0, yBuff) # 'x' is the time-series data you are filtering\n",
    "\n",
    "\n",
    "    # count number of positive inflextions points (first derivative zero / second neg)\n",
    "    dy = np.diff(filtY)\n",
    "    dy[dy>0] = 1\n",
    "    dy[dy<0] = -1\n",
    "    ddy = np.diff(dy)\n",
    "\n",
    "    # this counts just one legg steps\n",
    "    #ddy[ddy>0] = 0\n",
    "\n",
    "    # if we assume a backswing == a forward swing with the other leg\n",
    "    stepsToCount = ddy[startFrame:endFrame]\n",
    "    totalSteps = np.count_nonzero(stepsToCount)\n",
    "    print('Total Steps before minimum correction = %d'%totalSteps)\n",
    "\n",
    "    A = np.diff(np.nonzero(stepsToCount))[0]\n",
    "    newTotalSteps = len(A[A>threshStepSamples])\n",
    "    print('Total Steps after minimum correction = %d'%newTotalSteps)\n",
    "    return [filtY, dy, ddy, A]    \n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manually select unique color pixel to track in ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idxList = []\n",
    "roiList = []\n",
    "\n",
    "def draw_circle(event,x,y,flags,param):\n",
    "    global idxList\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        cv2.circle(roiScale,(x,y),3,(255,0,0),-1)\n",
    "        idxList.append([x,y])\n",
    "\n",
    "def draw_roi(event,x,y,flags,param):\n",
    "    global roiList\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        cv2.circle(frame,(x,y),3,(255,0,0),-1)\n",
    "        print(x,y)\n",
    "        roiList.append([x,y])     \n",
    "        \n",
    "        \n",
    "# automate this with user input based on time maybe\n",
    "frameOffset = 0\n",
    "\n",
    "        \n",
    "# grab and display a frame during run\n",
    "cap = cv2.VideoCapture(filename)\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES,frameOffset)\n",
    "fs = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "ret,frame = cap.read()\n",
    "\n",
    "cv2.namedWindow('select roi')\n",
    "cv2.setMouseCallback('select roi',draw_roi)\n",
    "while(1):\n",
    "    cv2.imshow('select roi', frame)\n",
    "    k = cv2.waitKey(1) & 0xFF\n",
    "    if k == 27:\n",
    "        break\n",
    "cv2.destroyAllWindows() \n",
    "\n",
    "        \n",
    "c,r = roiList[0]\n",
    "w,h = roiList[1]\n",
    "roiPoints = (r,c,h,w)\n",
    "\n",
    "# set up the ROI for tracking\n",
    "roi = frame[r:h,c:w]\n",
    "\n",
    "cv2.namedWindow('select track points')\n",
    "cv2.setMouseCallback('select track points',draw_circle)\n",
    "roiScale = cv2.resize(roi, None,fx=2, fy=2, interpolation = cv2.INTER_CUBIC)\n",
    "roiPristine = roiScale.copy()\n",
    "\n",
    "while(1):\n",
    "    cv2.imshow('select track points', roiScale)\n",
    "    k = cv2.waitKey(1) & 0xFF\n",
    "    if k == ord('m'):\n",
    "        mode = not mode\n",
    "    elif k == 27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows() \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize selected Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for idx in idxList:    \n",
    "    plotMask(idx, roiPristine, offset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process (track, filter, and count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "selectedIdx = int(input('Select Optimal Color to Track '))  \n",
    "\n",
    "offset = 30\n",
    "[xBuff, yBuff] = trackSteps(idxList[selectedIdx], roiPristine, True, filename, roiPoints)\n",
    "\n",
    "#[smooth, slope, inflection, steps] =  countSteps(yBuff, fs, startFrame, endFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "S = pickle.load(open(filename[:-4]+'_buffFile.pkl', 'rb'))\n",
    "superFilter = []\n",
    "\n",
    "for buff in S:\n",
    "    xBuff,yBuff = buff\n",
    "    superFilter.append(countSteps(yBuff, startFrame, endFrame))\n",
    "\n",
    "%run 'import_plots.ipynb'\n",
    "\n",
    "sns.set_style(\"white\")\n",
    "sns.set_style(\"ticks\")\n",
    "fig, ax = plt.subplots(figsize=(11, 6))\n",
    "\n",
    "for filt in superFilter:\n",
    "    smooth, slope, inflection, steprate = filt\n",
    "    plt.hist(steprate, 100);\n",
    "\n",
    "plt.ylabel('Number Step', fontsize=14)\n",
    "plt.tick_params(axis='y', labelsize=12)\n",
    "plt.tick_params(which='major', axis='x', labelsize=12)\n",
    "plt.grid(axis='y',color='grey', linestyle='--', lw=0.5, alpha=0.5)\n",
    "plt.grid(axis='x',color='grey', linestyle='--', lw=0.5, alpha=0.5)\n",
    "sns.despine(trim=True, left=True, bottom=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Debug Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "# plt.plot(filtY)\n",
    "#plt.plot(filtY[20000:])\n",
    "plt.plot(filtY,'.-')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%run 'import_plots.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ipplot(S[3][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ipplot(ddy.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ipplot(filtY.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "B = [len(A[A>thresh]) for thresh in np.arange(30)]\n",
    "pplot(B);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(A,100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.where(A==29)\n",
    "A[1798]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idx = np.nonzero(stepsToCount)[0]\n",
    "idx[np.where(A==29)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fudge  = (len(xBuff)/fs) / 878."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "125/fs/fudge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "S = pickle.load(open('buffFile', 'rb'))\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
