{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step Count From Video\n",
    "\n",
    "### Overview\n",
    "Count the number of steps from a carefully controlled treadmill video. We identify a unique color in a region of interest (ROI), such as a shoelace. This color is tracked and the number of zero crossing (normalized) is correlated to a step. Specifically create an object around the the color of interest and track the trajectory in Euclidean space (x,y). Zero crossings are estimated by identifing the zero slope and inflection point of the y coordinate time series.\n",
    "\n",
    "### Improvements\n",
    "- <font color='red'>Automate ROI (DONE)</font> \n",
    "- Physically place unique color tags (neon stickers) on shoes during test-\n",
    "- Automate start and stop frames\n",
    "- Consider contours in Visualization\n",
    "- Test accuracy over various test scenarios\n",
    "- Consider transforming to HSV space to mitigate shadows\n",
    "- Automate setting of kernel size (for object detect) and mask threshold\n",
    "- Use history to track trajectory\n",
    "- <font color='red'>Minimum stride rate (DONE)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and System Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using OpenCV version 3.1.0\n",
      "Using Numpy version  1.11.1\n",
      "Using python verion  3.5.2 \n",
      "(Anaconda 4.2.0 (x86_64))\n",
      " (default, Jul  2 2016, 17:52:12) \n",
      "[GCC 4.2.1 Compatible Apple LLVM 4.2 (clang-425.0.28)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib osx\n",
    "print('Using OpenCV version %s'%cv2.__version__)\n",
    "print('Using Numpy version  %s'%np.__version__)\n",
    "ver = sys.version.split('|')\n",
    "print('Using python verion  %s'%ver[0])\n",
    "print('('+ver[1]+')')\n",
    "print(ver[2])\n",
    "\n",
    "# system parameters\n",
    "# Display tracking Video and Debug Messages\n",
    "#DISP = True\n",
    "DISP = True\n",
    "\n",
    "# size of kernel\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (8,8))\n",
    "\n",
    "# min blob size\n",
    "minBlobArea = 5\n",
    "\n",
    "# +/- in RGB color space\n",
    "offset = 20\n",
    "\n",
    "# file to interrogate\n",
    "filename = './Downloads/StepCountRateVideos/20161110_152638 KeDe Step Count.mp4'\n",
    "\n",
    "# frame window over which actual steps are taken\n",
    "startFrame = 500\n",
    "endFrame = 25700"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def onclick(event):\n",
    "    print('button=%d, x=%d, y=%d, xdata=%f, ydata=%f' %\n",
    "          (event.button, event.x, event.y, event.xdata, event.ydata))\n",
    "    global idxList\n",
    "    idxList.append([event.xdata, event.ydata])\n",
    "#    global axRef\n",
    "#    axRef.scatter(int(event.xdata), int(event.ydata))\n",
    "    \n",
    "def getPoint(x,y,img):\n",
    "    temp = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    return temp[x,y]\n",
    "\n",
    "def getLineSegment(x1,x2,y,img):\n",
    "    temp = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    return temp[x1:x2,y]\n",
    "\n",
    "def colorFromIdx(idx, frame):\n",
    "    x,y = idx \n",
    "    return frame[int(y), int(x), :]\n",
    "\n",
    "def plotMask(idx, frameColor, frame, offset):\n",
    "    idColor = colorFromIdx(idx, frameColor)\n",
    "    mask = np.zeros(frame.shape)\n",
    "    for ii,color in enumerate(idColor):\n",
    "        mask[:,:,ii] = (frame[:,:,ii] > color-offset) & (frame[:,:,ii]<color+offset)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.imshow(np.sum(mask,axis=2))\n",
    "    plt.title(str(idx))\n",
    "\n",
    "def plotRefPoint(idx, ax):\n",
    "    x,y = idx \n",
    "    ax.scatter(int(x), int(y))\n",
    "    \n",
    "def getMask(idColor, frame, offset):\n",
    "    mask = np.zeros(frame.shape)\n",
    "    for ii,color in enumerate(idColor):\n",
    "        mask[:,:,ii] = (frame[:,:,ii] > color-offset) & (frame[:,:,ii]<color+offset) \n",
    "    mask = np.sum(mask, axis=2) ==3\n",
    "    return mask\n",
    "\n",
    "def getBlob(mask):\n",
    "    blob = cv2.dilate(mask.astype(np.uint8), kernel)\n",
    "    return blob\n",
    "\n",
    "def getCentroid(blob):\n",
    "    temp = blob.copy()\n",
    "    temp[temp==0] = 255\n",
    "    temp[temp==1] = 0\n",
    "    keypoints = detector.detect(temp)\n",
    "#    keypoints = detector.detect(blob)\n",
    "    return keypoints\n",
    "\n",
    "\n",
    "# Set up the SimpleBlobdetector with default parameters.\n",
    "params = cv2.SimpleBlobDetector_Params()\n",
    "\n",
    "# Change thresholds\n",
    "params.minThreshold = 0;\n",
    "params.maxThreshold = 256;\n",
    "\n",
    "# Filter by Area.\n",
    "params.filterByArea = True\n",
    "params.minArea = minBlobArea\n",
    "\n",
    "# Filter by Circularity\n",
    "params.filterByCircularity = False\n",
    "params.minCircularity = 0.1\n",
    "\n",
    "# Filter by Convexity\n",
    "params.filterByConvexity = False\n",
    "params.minConvexity = 0.5\n",
    "\n",
    "# Filter by Inertia\n",
    "params.filterByInertia = False\n",
    "params.minInertiaRatio = 0.5\n",
    "\n",
    "detector = cv2.SimpleBlobDetector_create(params)\n",
    "\n",
    "def trackSteps(idx, roiRef, DISP, filename, roiPoints):\n",
    "    \n",
    "    x,y = idx\n",
    "    r,c,h,w = roiPoints \n",
    "    idColor = colorFromIdx(idx, roiRef)\n",
    "    xBuff = [x]\n",
    "    yBuff = [y]\n",
    "    frameSkip = 0\n",
    "\n",
    "    cap = cv2.VideoCapture(filename)\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES,frameSkip)\n",
    "    ret,frame = cap.read()\n",
    "    count = frameSkip\n",
    "\n",
    "    while ret:\n",
    "        count = count + 1\n",
    "        roi = frame[r:h,c:w]\n",
    "\n",
    "        mask = getMask(idColor, roi, offset)\n",
    "        blob = getBlob(mask)\n",
    "        keypoints = getCentroid(blob)\n",
    "\n",
    "        # if we find any blobs\n",
    "        if keypoints:\n",
    "\n",
    "            # assume one and use that as the centroid\n",
    "            x,y = keypoints[0].pt\n",
    "\n",
    "            # if more than one find the one closest to the last one\n",
    "            minVal = float('inf')\n",
    "            for kp in keypoints:\n",
    "                x,y = kp.pt\n",
    "                dist = np.power((x-xBuff[-1]),2)+np.power((y-yBuff[-1]),2)\n",
    "                if dist < minVal:\n",
    "                    minVal = dist\n",
    "                    xOut = x\n",
    "                    yout = y\n",
    "\n",
    "\n",
    "        else:\n",
    "\n",
    "            # if no blob found then use the old value\n",
    "            # mostly we get here because the blob touches the edge of the image\n",
    "            x = xBuff[-1]\n",
    "            y = yBuff[-1]\n",
    "            #input('')\n",
    "\n",
    "        xBuff.append(x)\n",
    "        yBuff.append(y)\n",
    "           \n",
    "        if DISP and (count%1000 == 0):\n",
    "            print(count)\n",
    "\n",
    "        if DISP:\n",
    "\n",
    "            fr,fc,t = frame.shape\n",
    "            frameMask = np.ones([fr,fc],dtype=np.uint8)      \n",
    "            frameMask[r:h,c:w] = cv2.bitwise_xor(blob,1)        \n",
    "            new = cv2.circle(cv2.bitwise_and(frame, frame, mask=frameMask), (int(x)+c,int(y)+r), 5, 255, -1)\n",
    "            cv2.imshow('frame',new)\n",
    "\n",
    "    #         if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "    #             break\n",
    "\n",
    "            k = cv2.waitKey(0)\n",
    "            if k == 27:         # wait for ESC key to exit\n",
    "                cv2.destroyAllWindows()\n",
    "                break\n",
    "            elif k == ord('n'): # wait for 's' for next frame\n",
    "                t = 1\n",
    "\n",
    "        ret,frame = cap.read()\n",
    "\n",
    "\n",
    "    cap.release()\n",
    "    return [xBuff, yBuff]\n",
    "\n",
    "def trackPoints(filename, frameOffset, roiPoints):\n",
    "    r,h,c,w = roiPoints \n",
    "\n",
    "    # grab and display a frame during run\n",
    "    cap = cv2.VideoCapture(filename)\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES,frameOffset)\n",
    "    fs = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    ret,frame = cap.read()\n",
    "    # set up the ROI for tracking\n",
    "    roiRef = frame[r:r+h, c:c+w]\n",
    "           \n",
    "    cv2.namedWindow('select track points')\n",
    "    cv2.setMouseCallback('select track points',draw_circle)\n",
    "\n",
    "    while(1):\n",
    "        cv2.imshow('image',roiRef)\n",
    "        k = cv2.waitKey(1) & 0xFF\n",
    "        if k == ord('m'):\n",
    "            mode = not mode\n",
    "        elif k == 27:\n",
    "            break\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    " \n",
    "    # mouse click on columns to histogram\n",
    "    return [roiRef, fs]\n",
    "\n",
    "def countSteps(yBuff, startFrame, endFrame):\n",
    "    # user input to figure out true offset\n",
    "    threshStepSamples = 4 #min number of sample per stride based on max step rate\n",
    "\n",
    "    # low pass filter to smooth\n",
    "    N=10\n",
    "    fc = fs/600.\n",
    "\n",
    "    import scipy.signal as sp\n",
    "\n",
    "    # use firwin with arbitrary Fs\n",
    "    h=sp.firwin( numtaps=N, cutoff=fc, nyq=fs/2)\n",
    "    filtY=sp.lfilter( h, 1.0, yBuff) # 'x' is the time-series data you are filtering\n",
    "\n",
    "\n",
    "    # count number of positive inflextions points (first derivative zero / second neg)\n",
    "    dy = np.diff(filtY)\n",
    "    dy[dy>0] = 1\n",
    "    dy[dy<0] = -1\n",
    "    ddy = np.diff(dy)\n",
    "\n",
    "    # this counts just one legg steps\n",
    "    #ddy[ddy>0] = 0\n",
    "\n",
    "    # if we assume a backswing == a forward swing with the other leg\n",
    "    stepsToCount = ddy[startFrame:endFrame]\n",
    "    totalSteps = np.count_nonzero(stepsToCount)\n",
    "    print('Total Steps before minimum correction = %d'%totalSteps)\n",
    "\n",
    "    A = np.diff(np.nonzero(stepsToCount))[0]\n",
    "    newTotalSteps = len(A[A>threshStepSamples])\n",
    "    print('Total Steps after minimum correction = %d'%newTotalSteps)\n",
    "    return [filtY, dy, ddy, A]    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manually select unique color pixel to track in ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180 302\n",
      "321 447\n"
     ]
    }
   ],
   "source": [
    "idxList = []\n",
    "roiList = []\n",
    "\n",
    "def draw_circle(event,x,y,flags,param):\n",
    "    global idxList\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        cv2.circle(roiScale,(x,y),3,(255,0,0),-1)\n",
    "        idxList.append([x,y])\n",
    "\n",
    "def draw_roi(event,x,y,flags,param):\n",
    "    global roiList\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        cv2.circle(frame,(x,y),3,(255,0,0),-1)\n",
    "        print(x,y)\n",
    "        roiList.append([x,y])     \n",
    "        \n",
    "        \n",
    "# automate this with user input based on time maybe\n",
    "frameOffset = 0\n",
    "\n",
    "        \n",
    "# grab and display a frame during run\n",
    "cap = cv2.VideoCapture(filename)\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES,frameOffset)\n",
    "fs = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "ret,frame = cap.read()\n",
    "\n",
    "cv2.namedWindow('select roi')\n",
    "cv2.setMouseCallback('select roi',draw_roi)\n",
    "while(1):\n",
    "    cv2.imshow('select roi', frame)\n",
    "    k = cv2.waitKey(1) & 0xFF\n",
    "    if k == 27:\n",
    "        break\n",
    "cv2.destroyAllWindows() \n",
    "\n",
    "        \n",
    "c,r = roiList[0]\n",
    "w,h = roiList[1]\n",
    "roiPoints = (r,c,h,w)\n",
    "\n",
    "# set up the ROI for tracking\n",
    "roi = frame[r:h,c:w]\n",
    "\n",
    "cv2.namedWindow('select track points')\n",
    "cv2.setMouseCallback('select track points',draw_circle)\n",
    "roiScale = cv2.resize(roi, None,fx=2, fy=2, interpolation = cv2.INTER_CUBIC)\n",
    "roiPristine = roiScale.copy()\n",
    "\n",
    "while(1):\n",
    "    cv2.imshow('select track points', roiScale)\n",
    "    k = cv2.waitKey(1) & 0xFF\n",
    "    if k == ord('m'):\n",
    "        mode = not mode\n",
    "    elif k == 27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize selected Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for idx in idxList:    \n",
    "    plotMask(idx, roiPristine, frame, offset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Track "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "superBuff = []\n",
    "for ii,idx in enumerate(idxList):\n",
    "    superBuff.append(trackSteps(idx, roiPristine, False, filename, roiPoints))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(filename[:-4]+'_buffFile1.pkl','wb') as f:\n",
    "    pickle.dump(superBuff,f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Filter and count steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Steps before minimum correction = 3237\n",
      "Total Steps after minimum correction = 2545\n",
      "Total Steps before minimum correction = 3252\n",
      "Total Steps after minimum correction = 2329\n",
      "Total Steps before minimum correction = 3126\n",
      "Total Steps after minimum correction = 2133\n",
      "Total Steps before minimum correction = 3810\n",
      "Total Steps after minimum correction = 2632\n"
     ]
    }
   ],
   "source": [
    "superFilter = []\n",
    "startFrame = 670\n",
    "endFrame = 25700\n",
    "\n",
    "for buff in superBuff:\n",
    "    xBuff,yBuff = buff\n",
    "    superFilter.append(countSteps(yBuff, startFrame, endFrame))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Debug Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x116d8dc18>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "NameError",
     "evalue": "name 'filtY' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-cc18b1feb488>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# plt.plot(filtY)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#plt.plot(filtY[20000:])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'.-'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'filtY' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x116d8dc18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "# plt.plot(filtY)\n",
    "#plt.plot(filtY[20000:])\n",
    "plt.plot(filtY,'.-')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%run 'import_plots.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ipplot(ddy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ipplot(smooth.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "B = [len(A[A>thresh]) for thresh in np.arange(20)]\n",
    "pplot(B);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.where(A>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pplot(ddy[1:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.arange(len(yBuff))/fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fudge  = (len(xBuff)/fs) / 878."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fs=18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Steps before minimum correction = 3251\n",
      "Total Steps after minimum correction = 2557\n",
      "Total Steps before minimum correction = 3267\n",
      "Total Steps after minimum correction = 2340\n",
      "Total Steps before minimum correction = 3140\n",
      "Total Steps after minimum correction = 2144\n",
      "Total Steps before minimum correction = 3831\n",
      "Total Steps after minimum correction = 2644\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1200b8cf8>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x11ffbeeb8>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1200c39b0>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x12229c240>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x120091550>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "S = pickle.load(open(filename[:-4]+'_buffFile1.pkl', 'rb'))\n",
    "superFilter = []\n",
    "# startFrame = 500\n",
    "# endFrame = 25700\n",
    "\n",
    "for buff in S:\n",
    "    xBuff,yBuff = buff\n",
    "    superFilter.append(countSteps(yBuff, startFrame, endFrame))\n",
    "\n",
    "%run 'import_plots.ipynb'\n",
    "%matplotlib osx\n",
    "\n",
    "sns.set_style(\"white\")\n",
    "sns.set_style(\"ticks\")\n",
    "fig, ax = plt.subplots(figsize=(11, 6))\n",
    "\n",
    "for filt in superFilter:\n",
    "    smooth, slope, inflection, steprate = filt\n",
    "#     B = [len(steprate[steprate>thresh]) for thresh in np.arange(20)]\n",
    "#     plt.plot(B,marker='.')\n",
    "    plt.plot(smooth)\n",
    "plt.ylabel('Number Step', fontsize=14)\n",
    "plt.tick_params(axis='y', labelsize=12)\n",
    "plt.tick_params(which='major', axis='x', labelsize=12)\n",
    "plt.grid(axis='y',color='grey', linestyle='--', lw=0.5, alpha=0.5)\n",
    "plt.grid(axis='x',color='grey', linestyle='--', lw=0.5, alpha=0.5)\n",
    "sns.despine(trim=True, left=True, bottom=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "S = pickle.load(open('buffFile1', 'rb'))\n",
    "superFilter = []\n",
    "# startFrame = 500\n",
    "# endFrame = 25700\n",
    "\n",
    "for buff in S:\n",
    "    xBuff,yBuff = buff\n",
    "    superFilter.append(countSteps(yBuff, startFrame, endFrame))\n",
    "\n",
    "%run 'import_plots.ipynb'\n",
    "%matplotlib notebook\n",
    "\n",
    "sns.set_style(\"white\")\n",
    "sns.set_style(\"ticks\")\n",
    "fig, ax = plt.subplots(figsize=(11, 6))\n",
    "\n",
    "for filt in superFilter:\n",
    "    smooth, slope, inflection, steprate = filt\n",
    "    plt.hist(steprate, 100)\n",
    "\n",
    "plt.ylabel('Number Step', fontsize=14)\n",
    "plt.tick_params(axis='y', labelsize=12)\n",
    "plt.tick_params(which='major', axis='x', labelsize=12)\n",
    "plt.grid(axis='y',color='grey', linestyle='--', lw=0.5, alpha=0.5)\n",
    "plt.grid(axis='x',color='grey', linestyle='--', lw=0.5, alpha=0.5)\n",
    "sns.despine(trim=True, left=True, bottom=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {
    "f5012d93814141ab9030a290d9f5d23b": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
