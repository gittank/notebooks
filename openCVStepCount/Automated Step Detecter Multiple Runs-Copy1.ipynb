{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step Count From Video\n",
    "\n",
    "### Overview\n",
    "Count the number of steps from a carefully controlled treadmill video. We identify a unique color in a region of interest (ROI), such as a shoelace. This color is tracked and the number of zero crossing (normalized) is correlated to a step. Specifically create an object around the the color of interest and track the trajectory in Euclidean space (x,y). Zero crossings are estimated by identifing the zero slope and inflection point of the y coordinate time series.\n",
    "\n",
    "### Improvements\n",
    "- Automate ROI \n",
    "- Physically place unique color tags (neon stickers) on shoes during test-\n",
    "- Automate start and stop frames\n",
    "- Consider contours in Visualization\n",
    "- Test accuracy over various test scenarios\n",
    "- Consider transforming to HSV space to mitigate shadows\n",
    "- Automate setting of kernel size (for object detect) and mask threshold\n",
    "- Use history to track trajectory\n",
    "- <font color='red'>Minimum stride rate (DONE)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and System Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib osx\n",
    "print('Using OpenCV version %s'%cv2.__version__)\n",
    "print('Using Numpy version  %s'%np.__version__)\n",
    "ver = sys.version.split('|')\n",
    "print('Using python verion  %s'%ver[0])\n",
    "print('('+ver[1]+')')\n",
    "print(ver[2])\n",
    "\n",
    "# system parameters\n",
    "# Display tracking Video and Debug Messages\n",
    "#DISP = True\n",
    "DISP = False\n",
    "\n",
    "# size of kernel\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (8,8))\n",
    "\n",
    "# +/- in RGB color space\n",
    "offset = 20\n",
    "\n",
    "# file to interrogate\n",
    "filename = './Downloads/StepCountRateVideos/VID_20161121_104909 JuSa Step Rate 5.5-6.5.mp4'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def onclick(event):\n",
    "    print('button=%d, x=%d, y=%d, xdata=%f, ydata=%f' %\n",
    "          (event.button, event.x, event.y, event.xdata, event.ydata))\n",
    "    global idxList\n",
    "    idxList.append([event.xdata, event.ydata])\n",
    "#    global axRef\n",
    "#    axRef.scatter(int(event.xdata), int(event.ydata))\n",
    "    \n",
    "def getPoint(x,y,img):\n",
    "    temp = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    return temp[x,y]\n",
    "\n",
    "def getLineSegment(x1,x2,y,img):\n",
    "    temp = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    return temp[x1:x2,y]\n",
    "\n",
    "def colorFromIdx(idx, frame):\n",
    "    x,y = idx \n",
    "    return frame[int(y), int(x), :]\n",
    "\n",
    "def plotMask(idx, frame, offset):\n",
    "    idColor = colorFromIdx(idx, frame)\n",
    "    mask = np.zeros(frame.shape)\n",
    "    for ii,color in enumerate(idColor):\n",
    "        mask[:,:,ii] = (frame[:,:,ii] > color-offset) & (frame[:,:,ii]<color+offset)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.imshow(np.sum(mask,axis=2))\n",
    "    plt.title(str(idx))\n",
    "\n",
    "def plotRefPoint(idx, ax):\n",
    "    x,y = idx \n",
    "    ax.scatter(int(x), int(y))\n",
    "    \n",
    "def getMask(idColor, frame, offset):\n",
    "    mask = np.zeros(frame.shape)\n",
    "    for ii,color in enumerate(idColor):\n",
    "        mask[:,:,ii] = (frame[:,:,ii] > color-offset) & (frame[:,:,ii]<color+offset) \n",
    "    mask = np.sum(mask, axis=2) ==3\n",
    "    return mask\n",
    "\n",
    "def getBlob(mask):\n",
    "    blob = cv2.dilate(mask.astype(np.uint8), kernel)\n",
    "    return blob\n",
    "\n",
    "def getCentroid(blob):\n",
    "    temp = blob.copy()\n",
    "    temp[temp==0] = 255\n",
    "    temp[temp==1] = 0\n",
    "    keypoints = detector.detect(temp)\n",
    "#    keypoints = detector.detect(blob)\n",
    "    return keypoints\n",
    "\n",
    "\n",
    "# Set up the SimpleBlobdetector with default parameters.\n",
    "params = cv2.SimpleBlobDetector_Params()\n",
    "\n",
    "# Change thresholds\n",
    "params.minThreshold = 0;\n",
    "params.maxThreshold = 256;\n",
    "\n",
    "# Filter by Area.\n",
    "params.filterByArea = True\n",
    "params.minArea = 5\n",
    "\n",
    "# Filter by Circularity\n",
    "params.filterByCircularity = False\n",
    "params.minCircularity = 0.1\n",
    "\n",
    "# Filter by Convexity\n",
    "params.filterByConvexity = False\n",
    "params.minConvexity = 0.5\n",
    "\n",
    "# Filter by Inertia\n",
    "params.filterByInertia = False\n",
    "params.minInertiaRatio = 0.5\n",
    "\n",
    "detector = cv2.SimpleBlobDetector_create(params)\n",
    "\n",
    "def trackSteps(idx, roiRef, DISP, filename, roiPoints):\n",
    "    \n",
    "    x,y = idx\n",
    "    r,h,c,w = roiPoints \n",
    "    idColor = colorFromIdx(idx, roiRef)\n",
    "    xBuff = [x]\n",
    "    yBuff = [y]\n",
    "    frameSkip = 0\n",
    "\n",
    "    cap = cv2.VideoCapture(filename)\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES,frameSkip)\n",
    "    ret,frame = cap.read()\n",
    "    count = frameSkip\n",
    "\n",
    "    while ret:\n",
    "        count = count + 1\n",
    "        roi = frame[r:r+h, c:c+w]\n",
    "        mask = getMask(idColor, roi, offset)\n",
    "        blob = getBlob(mask)\n",
    "        keypoints = getCentroid(blob)\n",
    "\n",
    "        # if we find any blobs\n",
    "        if keypoints:\n",
    "\n",
    "            # assume one and use that as the centroid\n",
    "            x,y = keypoints[0].pt\n",
    "\n",
    "            # if more than one find the one closest to the last one\n",
    "            minVal = float('inf')\n",
    "            for kp in keypoints:\n",
    "                x,y = kp.pt\n",
    "                dist = np.power((x-xBuff[-1]),2)+np.power((y-yBuff[-1]),2)\n",
    "                if dist < minVal:\n",
    "                    minVal = dist\n",
    "                    xOut = x\n",
    "                    yout = y\n",
    "\n",
    "\n",
    "        else:\n",
    "\n",
    "            # if no blob found then use the old value\n",
    "            # mostly we get here because the blob touches the edge of the image\n",
    "            x = xBuff[-1]\n",
    "            y = yBuff[-1]\n",
    "            #input('')\n",
    "\n",
    "        xBuff.append(x)\n",
    "        yBuff.append(y)\n",
    "           \n",
    "        if DISP and (count%1000 == 0):\n",
    "            print(count)\n",
    "\n",
    "        if DISP:\n",
    "\n",
    "            fr,fc,t = frame.shape\n",
    "            frameMask = np.ones([fr,fc],dtype=np.uint8)      \n",
    "            frameMask[r:r+h,c:c+w] = cv2.bitwise_xor(blob,1)        \n",
    "            new = cv2.circle(cv2.bitwise_and(frame, frame, mask=frameMask), (int(x)+c,int(y)+r), 5, 255, -1)\n",
    "            cv2.imshow('frame',new)\n",
    "\n",
    "    #         if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "    #             break\n",
    "\n",
    "            k = cv2.waitKey(0)\n",
    "            if k == 27:         # wait for ESC key to exit\n",
    "                cv2.destroyAllWindows()\n",
    "                break\n",
    "            elif k == ord('n'): # wait for 's' for next frame\n",
    "                t = 1\n",
    "\n",
    "        ret,frame = cap.read()\n",
    "\n",
    "\n",
    "    cap.release()\n",
    "    return xBuff, yBuff\n",
    "\n",
    "def trackPoints(filename, frameOffset, roiPoints):\n",
    "    r,h,c,w = roiPoints \n",
    "\n",
    "    # grab and display a frame during run\n",
    "    cap = cv2.VideoCapture(filename)\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES,frameOffset)\n",
    "    fs = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    ret,frame = cap.read()\n",
    "    # set up the ROI for tracking\n",
    "    roiRef = frame[r:r+h, c:c+w]\n",
    "\n",
    "    figRef = plt.figure()\n",
    "    plt.title('Mouse Click on Possible Unique Pixels')\n",
    "    axRef = figRef.add_subplot(111)\n",
    "    axRef.imshow(roiRef)\n",
    "\n",
    "    # mouse click on columns to histogram\n",
    "    cid = figRef.canvas.mpl_connect('button_press_event', onclick);\n",
    "    return [figRef, roiRef]\n",
    "\n",
    "def countSteps(yBuff, startFrame, endFrame):\n",
    "    # user input to figure out true offset\n",
    "    threshStepSamples = 4 #min number of sample per stride based on max step rate\n",
    "\n",
    "    # low pass filter to smooth\n",
    "    N=10\n",
    "    fc = fs/600.\n",
    "\n",
    "    import scipy.signal as sp\n",
    "\n",
    "    # use firwin with arbitrary Fs\n",
    "    h=sp.firwin( numtaps=N, cutoff=fc, nyq=fs/2)\n",
    "    filtY=sp.lfilter( h, 1.0, yBuff) # 'x' is the time-series data you are filtering\n",
    "\n",
    "\n",
    "    # count number of positive inflextions points (first derivative zero / second neg)\n",
    "    dy = np.diff(filtY)\n",
    "    dy[dy>0] = 1\n",
    "    dy[dy<0] = -1\n",
    "    ddy = np.diff(dy)\n",
    "\n",
    "    # this counts just one legg steps\n",
    "    #ddy[ddy>0] = 0\n",
    "\n",
    "    # if we assume a backswing == a forward swing with the other leg\n",
    "    stepsToCount = ddy[startFrame:endFrame]\n",
    "    totalSteps = np.count_nonzero(stepsToCount)\n",
    "    print('Total Steps before minimum correction = %d'%totalSteps)\n",
    "\n",
    "    A = np.diff(np.nonzero(stepsToCount))[0]\n",
    "    newTotalSteps = len(A[A>threshStepSamples])\n",
    "    print('Total Steps after minimum correction = %d'%newTotalSteps)\n",
    "    return filtY, dy, ddy, A    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manually select unique color pixel to track in ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv2.EVE\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# grab and display a frame during run\n",
    "cap = cv2.VideoCapture(filename)\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES,300)\n",
    "fs = cap.get(cv2.CAP_PROP_FPS)\n",
    "ret,frame = cap.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# mouse callback function\n",
    "def draw_circle(event,x,y,flags,param):\n",
    "    print event\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        cv2.circle(img,(x,y),100,(255,0,0),-1)\n",
    "\n",
    "# Create a black image, a window and bind the function to window\n",
    "img = frame\n",
    "cv2.namedWindow('image')\n",
    "cv2.setMouseCallback('image',draw_circle)\n",
    "\n",
    "while(1):\n",
    "    cv2.imshow('image',img)\n",
    "    if cv2.waitKey(20) & 0xFF == 27:\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "events = [i for i in dir(cv2) if 'EVENT' in i]\n",
    "print(events)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idxList = []\n",
    "# automate both with user input\n",
    "frameOffset = 300\n",
    "r,h,c,w = 150,320,380,160 \n",
    "roiPoints =(r,h,c,w)\n",
    "\n",
    "figRef,roiRef = trackPoints(filename, frameOffset, roiPoints)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize selected Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for idx in idxList:    \n",
    "    plotMask(idx, roiRef, offset)\n",
    "    #plotRefPoint(idx,axRef)\n",
    "    \n",
    "#add roi selection here\n",
    "#add automated point selection and closing of images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Track "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "superBuff = []\n",
    "for ii,idx in enumerate(idxList):\n",
    "    superBuff.append(trackSteps(idx, roiRef, DISP, filename, roiPoints))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('buffFile'+filename,'wb') as f:\n",
    "    pickle.dump(superBuff,f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Filter and count steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "superFilter = []\n",
    "startFrame = 500\n",
    "endFrame = 25700\n",
    "\n",
    "for buff in superBuff:\n",
    "    xBuff,yBuff = buff\n",
    "    superFilter.append(countSteps(yBuff, startFrame, endFrame))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total Steps = 1979\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Debug Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "# plt.plot(filtY)\n",
    "#plt.plot(filtY[20000:])\n",
    "plt.plot(filtY,'.-')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%run 'import_plots.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ipplot(ddy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ipplot(filtY.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "B = [len(A[A>thresh]) for thresh in np.arange(20)]\n",
    "pplot(B);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.where(A>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pplot(ddy[1:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.arange(len(yBuff))/fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fudge  = (len(xBuff)/fs) / 878."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "125/fs/fudge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "S = pickle.load(open('buffFile', 'rb'))\n",
    "superFilter = []\n",
    "startFrame = 500\n",
    "endFrame = 25700\n",
    "\n",
    "for buff in S:\n",
    "    xBuff,yBuff = buff\n",
    "    superFilter.append(countSteps(yBuff, startFrame, endFrame))\n",
    "\n",
    "%run 'import_plots.ipynb'\n",
    "%matplotlib notebook\n",
    "\n",
    "sns.set_style(\"white\")\n",
    "sns.set_style(\"ticks\")\n",
    "fig, ax = plt.subplots(figsize=(11, 6))\n",
    "\n",
    "for filt in superFilter:\n",
    "    smooth, slope, inflection, steprate = filt\n",
    "    B = [len(steprate[steprate>thresh]) for thresh in np.arange(20)]\n",
    "    plt.plot(B,marker='.')\n",
    "\n",
    "plt.ylabel('Number Step', fontsize=14)\n",
    "plt.tick_params(axis='y', labelsize=12)\n",
    "plt.tick_params(which='major', axis='x', labelsize=12)\n",
    "plt.grid(axis='y',color='grey', linestyle='--', lw=0.5, alpha=0.5)\n",
    "plt.grid(axis='x',color='grey', linestyle='--', lw=0.5, alpha=0.5)\n",
    "sns.despine(trim=True, left=True, bottom=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fs=17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
